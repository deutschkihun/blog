---
title: '운영체제 (OS)'
date: '2022-04-19'
lastmod: '2022-04-19'
tags: ['OS']
draft: false
summary: 'OS 는 기술 인터뷰에서 지원자의 기본적인 컴퓨터 공학 지식을 확인하기 위해 자주 사용되는 주제중에 하나 입니다. 좀 더 자세하고 완벽한 인터뷰 준비를 위해서는 OS 관련 지식에 대해서 아는 것은 굉장히 중요하다고 생각합니다. 이번 포스팅을 통해 필자가 중요하다고 생각하는 OS 관련 배경지식에 대해서 알아보겠습니다.'
authors: ['default']
---

![tailwind-nextjs-banner](/static/os-basic/cover.jpg)

OS 는 기술 인터뷰에서 지원자의 기본적인 컴퓨터 공학 지식을 확인하기 위해 자주 사용되는 주제중에 하나 입니다. 좀 더 자세하고 완벽한 인터뷰 준비를 위해서는 OS 관련 지식에 대해서 아는 것은 굉장히 중요하다고 생각합니다. 이번 포스팅을 통해 필자가 중요하다고 생각하는 OS 관련 배경지식에 대해서 알아보겠습니다

## 1. 프로그램

어떤 작업을 하기 위해 실행하는 파일

## 2.프로세스

**프로세스** 는 자원을 할당받아 프로그램이 실행되고 있는 상태 인스턴스이다. 프로세스는 독립된 메모리 영역을 할당받고, 효율적으로 사용할 수 있도록 구조화하여 관리한다. 이를 **프로세스 주소 공간** 이라고 한다.

![handshake](/static/os-basic/process.png)

- **텍스트(Text) 영역**
- **데이터(Data) 영역**

- **힙(Heap) 영역**: 사용자에 의해 공간이 동적으로 할당 및 해제되는 동적 메모리 할당 영역이다.

- **스택(Stack) 영역**: 정적 메모리 할당

### PCB

- PCB 는 특정 프로세스에 대한 중요한 정보를 저장 하고 있는 운영체제의 자료구조이다.
- 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB 를 생성 한다.
- 프로세스는 CPU 를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU 를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB 에 저장하게 된다.
- 그리고 다시 CPU 를 할당받게 되면 PCB 에 저장되어있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다.

### **PCB 에 저장되는 정보**

- 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
- 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
- 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
- CPU 레지스터
- CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
- 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
- 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

## 3. 스레드

- 스레드는 프로세스의 실행 단위이다.
- 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유
- 스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성된
- 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유
- 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 **멀티스레딩**이라고 한다. 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다.

### **스택을 스레드마다 독립적으로 할당하는 이유**

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. **따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.**

### **PC Register 를 스레드마다 독립적으로 할당하는 이유**

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다. 스레드는 CPU 를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.

### **멀티 스레드**

- 프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다.
- 스레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용하여 데이터를 주고받을 수 있다.
- 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단하다. 심지어 스레드의 context switch 는 프로세스 context switch 와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
- 따라서 시스템의 throughput 이 향상되고 자원 소모가 줄어들며 자연스럽게 프로그램의 응답 시간이 단축된다. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠 수행하는 것이다.

### **멀티 스레딩의 문제점**

- 동일한 자원에 동시에 접근하는 일이 발생 할 수 있음
- 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정 할 수 있음

**그렇기 때문에 멀티스레딩 환경에서는 동기화 작업이 필요하다.**

### **멀티 스레드 vs 멀티 프로세스**

1. 멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다.

2. 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다.

## 4. 프로세스 Queue

RAM에 적재된 프로세스는 한 개가 아니기 때문에 프로세스가 CPU의 서비스를 받으려면 순서를 기다려야 한다.이 순서는 몇 가지 Queue에 의해 관리가 되며 크게 세 종류의 Queue가 있다.

- Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue : CPU 점유 순서를 기다리는 queue
- Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

위와 같이 여러 큐가 존재하는데, 각 큐 내부에 저장된 실제 데이터는 각 프로세스의 PCB가 저장되어 있다.

**그리고 이러한 순서를 기다리는 공간이 있다면 이 순서를 정해주는 알고리즘이 있어야 한다. 이러한 알고리즘을 스케줄링(Scheduling)이라 한다.**

## 5. 스케줄링

## **장기스케줄러(Long-term scheduler or job scheduler)**

메모리와 디스크 사이의 스케줄링을 담당.메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool 에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue 로 보낼지 결정하는 역할을 한다.

## **단기스케줄러(Short-term scheduler or CPU scheduler)**

CPU 와 메모리 사이의 스케줄링을 담당.
Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 작동 시킬지 결정.

## **중기스케줄러(Medium-term scheduler or Swapper)**

운영체제가 실행하는 동안 주기적으로 메인 메모리에 있는 전체 프로세스를 검사하여 보조기억장치로 옮길 프로세스를 찾아 옮긴다. 옮기는 기준은 여러가지 있겠지만 **대표적으로 장기간 사용하지 않는 프로세스가 있다.**

**이 기준으로 동작하는 것이 Swapping이다. 이는 메인 메모리에서 장시간 사용하지 않는 프로세스를 하드디스크로 옮겨주고(Swap out), 나중에 이 프로세스가 다시 사용되려고 하면 하드디스크에서 해당 프로세스를 다시 메인 메모리에 할당해준다.(Swap in)**

Swap out을 통해 메인 메모리의 공간이 생기므로 이를 더욱 효율적으로 사용할 수 있다. 만약 swap out된 프로세스가 다시 swap in으로 메인 메모리에 할당하려고 할 때 이전의 공간으로 할당되는 것을 보장하지는 않는다. 왜냐하면 위에 말했듯이 swap out으로 생긴 메모리 공간은 다른 프로세스가 사용할 수 있기 때문이다.

## 6. CPU 스케줄링

CPU를 사용하려고 하는 프로세스들 사이의 우선순위를 관리하는 작업을 말한다. Ready Queue 에 있는 프로세스들이 CPU 스케줄링의 대상이 된다.

### FIFO (First In First Out) 스케줄링

가장 간단한 스케줄링 기법으로 , 먼저 대기 큐에 들어온 작업에게 CPU를 먼저 할당하는 비선점 스케줄링 방식 (선입선출)

### SJF (Shortest Job First) 스케줄링

최단작업 우선. 실행시간이 짧은 프로세스 순서로 CPU를 할당하는 비선점형 스케줄링

### HRN (Highest Response Ratio Next) 스케줄링

기다린 시간 & CPU 사용시간으로 우선순위를 설정한 비선점형 스케줄링

### RR (Round Robin) 스케줄링

FIFO 스케줄링 기법을 Preemptive(선점형)기법으로 구현한 스케줄링 방법으로, 프로세스는 FIFO형태로 대기 큐에 적재되지만, 주어진 시간 할당량(time slice)안에 작업을 마쳐야 하며, 할당량을 다 소비하고도 작업이 끝나지 않은 프로세스는 다시 대기 큐의 맨 뒤로 되돌아간다.

## 7. 동기 vs 비동기

해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.

Sync vs Async
일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우를 동기 라고 표현하고 그렇지 않은 경우에 대해서 비동기 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미한다. 비동기의 경우, blocking되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

## 8.메모리 관리

각각의 **프로세스** 는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, **운영체제** 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.

1. **Swapping** : 메모리의 관리를 위해 사용되는 기법. 표준 Swapping 방식으로는 round-robin 과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(e.g. 하드디스크)로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.

> 이 과정을 **swap** (**스왑시킨다**) 이라 한다. 주 기억장치(RAM)으로 불러오는 과정을 **swap-in**, 보조 기억장치로 내보내는 과정을 **swap-out** 이라 한다. swap 에는 큰 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할때 Swapping 이 시작된다.

2. **단편화** (**Fragmentation**) : 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용 하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것이 **단편화** 이다. 단편화는 2 가지 종류로 나뉜다.

| `Process A` | free | `Process B` | free | `Process C` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | `Process D` |
| ----------- | ---- | ----------- | ---- | ----------- | :--------------------------------------------------------------------------------------: | ----------- |

- 외부 단편화: 메모리 공간 중 사용하지 못하게 되는 일부분. 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 **분산되어 있을때 발생한다고 볼 수 있다.**
- 내부 단편화: 프로세스가 사용하는 메모리 공간 에 포함된 남는 부분. 예를들어 **메모리 분할 자유 공간이 10,000B 있고 Process A 가 9,998B 사용하게되면 2B 라는 차이** 가 존재하고, 이 현상을 내부 단편화라 칭한다.

압축 : 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론 이지만, 작업효율이 좋지 않다. (위의 메모리 현황이 압축을 통해 아래의 그림 처럼 바뀌는 효과를 가질 수 있다)

| `Process A` | `Process B` | `Process C` | `Process D` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; |
| ----------- | ----------- | ----------- | :---------: | ------------------------------------------------------------------------------------------------------------------ |

### Paging(페이징)

하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법이다.
외부 단편화와 압축 작업을 해소 하기 위해 생긴 방법론으로, 물리 메모리는 Frame 이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지)

페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있다.

---

## 9.가상 메모리

가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법** 이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다.

#### 프로그램의 일부분만 메모리에 올릴 수 있다면...

- 물리 메모리 크기에 제약받지 않게 된다.
- 더 많은 프로그램을 동시에 실행할 수 있게 된다. 이에 따라 `응답시간`은 유지되고, `CPU 이용률`과 `처리율`은 높아진다.
- swap에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다.

#### 가상 주소 공간

- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다.
  프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다.
- 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 하자.
  하지만 실행까지에 필요한 메모리 공간`(Heap영역, Stack 영역, 코드, 데이터)`의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해할 수 있겠다.

### Demand Paging(요구 페이징)

프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을 `요구 페이징`이라 하며, 가상 메모리 시스템에서 많이 사용된다. 그리고 가상 메모리는 대개 페이지로 관리된다.
요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. **한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.**

프로세스 내의 개별 페이지들은 `페이저(pager)`에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로써, **사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다.**

#### Page fault trap(페이지 부재 트랩)

### 페이지 교체

`요구 페이징` 에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 `page fault(페이지 부재)`가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다. 하지만, 만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 아래와 같은 방법으로 이루워진다.

1.  디스크에서 필요한 페이지의 위치를 찾는다
1.  빈 페이지 프레임을 찾는다.
    1.  `페이지 교체 알고리즘`을 통해 희생될(victim) 페이지를 고른다.
    1.  희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.
1.  새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
1.  사용자 프로세스 재시작

## 10.캐시의 지역성

### 캐시의 지역성 원리

캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리이다. 이러한 역할을 수행하기 위해서는 CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU 가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.

이 때 `적중율(Hit rate)`을 극대화 시키기 위해 데이터 `지역성(Locality)의 원리`를 사용한다. 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access 하지 않는다는 특성을 기본으로 한다. 즉, `Locality`란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

이 데이터 지역성은 대표적으로 시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)으로 나뉜다.

- 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.
- 공간 지역성 : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

### Caching line

언급했듯이 캐시(cache)는 프로세서에 가까이 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소이다. 하지만 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 된다. 즉, 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력할 수 있어야 한다.

그렇기 때문에 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 `묶음`으로 저장하게 되는데 이를 **캐싱 라인** 이라고 한다.
종류로는 대표적으로 세 가지 방식이 존재한다.

1.  Full Associative
2.  Set Associative
3.  Direct Map

## 11.시스템 콜(system call)

- 시스템 콜은 운영체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다. 즉, 커널 영역의 기능을 사용자 모드에서 사용할 수 있게 해준다.

- 보통 일반적으로 사용하는 프로그램은 응용 프로그램이다. 유저레벨의 프로그램은 유저레벨의 함수들 만으로는 많은 기능을 구현하기 힘들기에 커널의 도움을 반드시 받아야한다. 이러한 작업은 유저 모드에서는 수행할 수 없고, 커널 모드로 전환한 후에 수행할 수 있는 권한이 생긴다. 커널 모드를 통한 이러한 작업은 반드시 시스템 콜을 통해 수행하도록 설계되어 있다.

## 12. IPC (Inter Process Communication)

- 프로세스 간 통신(Inter-Process Communication, IPC) 이란 프로세스들 사이에 서로 데이터를 주고받는 행위 또는 그에 대한 방법이나 경로를 뜻한다.

- 프로세스(Process) 는 독립적으로 실행되는 객체이지만 정보 공유, 계산 속도 향상, 모듈성, 편의성 들을 위해 통신을 필요로 할 수 있으며, 독립적인 프로세스 간의 통신을 위해서는 데이터를 교환하는 IPC 메커니즘이 필요하다.

## 13. Race Condition

Race Condition이란 여러 개의 프로세스가 공통 자원을 동시 접근하여 읽거나, 쓰는 경우 어떤 순서로 접근했는지에 따라서 실행 결과가 달라지는 상황이다. 즉, 공통 자원을 놓고 경쟁하는 상태이다.

## 14. Blocking / Non-blocking

한 작업이 다른 작업을 호출했을 때 제어권이 어디에 있는지에 따른 서로 다른 방식이다.

- **Blocking**
  호출된 함수가 계속 제어권을 갖고, 기존 함수는 대기한다.  
  호출된 함수가 기존 함수를 **Block 한다**.
- **Non-blocking**
  호출된 함수가 제어권을 바로 반환하여 기존 함수가 다른 작업을 수행할 수 있다.  
  호출된 함수가 기존 함수를 **Block 하지 않는다**.

## 15. 세마포어(Semaphore) & 뮤텍스(Mutex)

컴퓨터를 사용하면 여러 프로세스와 스레드들이 바쁘게 동작한다. 그 과정에서 프로세스 간 메시지를 전송하거나, 공유메모리를 통해 공유된 자원에 여러 개의 프로세스가 동시에 접근할 때, Critical Section 문제가 발생할 수 있다.
**critical section은 동시에 접근하면 안되는 공유 자원에 접근하는 코드블럭을 의미한다.**

이를 해결하기 위해 데이터에 한 번에 하나의 프로세스 혹은 스레드만 접근할 수 있도록 제한을 두는 동기화 방식을 취해야 한다.
**이 동기화 방식에 대표적으로 뮤텍스(Mutex)와 세마포어(Semaphore)가 있다.**

### 뮤텍스(mutex)

공유 자원의 데이터 혹은 critical section에 하나의 프로세스나 스레드만 접근하도록 막아준다. 즉, 여러 프로세스나 스레드들이 서로 겹치지 않고 단독으로 실행하도록 상호배제를 보장한다.

### 세마포어(Semaphore)

공유 자원의 데이터 혹은 critical section에 여러 프로세스나 스레드만 접근하도록 막아준다.
동시에 접근할 수 있는 프로세스나 스레드의 수를 세마포어 변수를 통해 관리하며 상호배제를 보장한다.

감사합니다.

#### reference

- [Interview_Question_for_Beginner](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%ED%9)

- [프로세스와 스케줄링](https://velog.io/@xxhaileypark/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81)

- [세마포어(Semaphore) & 뮤텍스(Mutex)](<https://github.com/da-in/tech-interview-study/blob/main/Tech%20Interview%20Cheat%20Sheet/Operating%20System/%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4(Semaphore)%20%26%20%EB%AE%A4%ED%85%8D%EC%8A%A4(Mutex).md>)
